{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Networks for Patches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#global imports\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorflow.contrib.learn as skflow\n",
    "from sklearn.preprocessing import normalize\n",
    "from sklearn.metrics import mean_squared_error, r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from util import PatchesDataLoader, PatchesSKLearner"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data_path = '/home/jacky/ws/patches/data/'\n",
    "pdl = PatchesDataLoader(0.25, data_path, [i for i in range(1)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def one_hot(types, labels):\n",
    "    result = np.zeros((labels.shape[0], len(types)))\n",
    "    for i in range(labels.shape[0]):\n",
    "        result[i][types[labels[i]]] = 1\n",
    "    return result        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fc_tr_1h = one_hot([0, 1], pdl.labels['fc']['tr'])\n",
    "fc_t_1h = one_hot([0, 1], pdl.labels['fc']['t'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pfc_10_tr = pdl.labels['pfc_10']['tr'].reshape(-1, 1)\n",
    "pfc_10_t = pdl.labels['pfc_10']['t'].reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DNN For Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batch_size = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "clf = skflow.TensorFlowDNNClassifier(hidden_units=[500, 200], n_classes=2, batch_size=batch_size, steps=5000,\n",
    "                                    optimizer=\"Adam\", learning_rate=0.001, dropout=0.25, continue_training=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step #99, avg. train loss: 0.24250\n",
      "Step #199, avg. train loss: 0.14069\n",
      "Step #299, avg. train loss: 0.12051\n",
      "Step #400, epoch #1, avg. train loss: 0.11671\n",
      "Step #500, epoch #1, avg. train loss: 0.10248\n",
      "Step #600, epoch #1, avg. train loss: 0.10545\n",
      "Step #700, epoch #2, avg. train loss: 0.09329\n",
      "Step #800, epoch #2, avg. train loss: 0.09174\n",
      "Step #900, epoch #2, avg. train loss: 0.09603\n",
      "Step #1000, epoch #2, avg. train loss: 0.08778\n",
      "Step #1100, epoch #3, avg. train loss: 0.08880\n",
      "Step #1200, epoch #3, avg. train loss: 0.08292\n",
      "Step #1300, epoch #3, avg. train loss: 0.08670\n",
      "Step #1400, epoch #4, avg. train loss: 0.08989\n",
      "Step #1500, epoch #4, avg. train loss: 0.08192\n",
      "Step #1600, epoch #4, avg. train loss: 0.08211\n",
      "Step #1700, epoch #4, avg. train loss: 0.07573\n",
      "Step #1800, epoch #5, avg. train loss: 0.06987\n",
      "Step #1900, epoch #5, avg. train loss: 0.07815\n",
      "Step #2000, epoch #5, avg. train loss: 0.07699\n",
      "Step #2100, epoch #6, avg. train loss: 0.08023\n",
      "Step #2200, epoch #6, avg. train loss: 0.07087\n",
      "Step #2300, epoch #6, avg. train loss: 0.07597\n",
      "Step #2400, epoch #6, avg. train loss: 0.07016\n",
      "Step #2500, epoch #7, avg. train loss: 0.07134\n",
      "Step #2600, epoch #7, avg. train loss: 0.07323\n",
      "Step #2700, epoch #7, avg. train loss: 0.06554\n",
      "Step #2800, epoch #8, avg. train loss: 0.07525\n",
      "Step #2900, epoch #8, avg. train loss: 0.06994\n",
      "Step #3000, epoch #8, avg. train loss: 0.06581\n",
      "Step #3100, epoch #8, avg. train loss: 0.06892\n",
      "Step #3200, epoch #9, avg. train loss: 0.06438\n",
      "Step #3300, epoch #9, avg. train loss: 0.06230\n",
      "Step #3400, epoch #9, avg. train loss: 0.06802\n",
      "Step #3500, epoch #10, avg. train loss: 0.06688\n",
      "Step #3600, epoch #10, avg. train loss: 0.05772\n",
      "Step #3700, epoch #10, avg. train loss: 0.05806\n",
      "Step #3800, epoch #10, avg. train loss: 0.06935\n",
      "Step #3900, epoch #11, avg. train loss: 0.05740\n",
      "Step #4000, epoch #11, avg. train loss: 0.06310\n",
      "Step #4100, epoch #11, avg. train loss: 0.06543\n",
      "Step #4200, epoch #12, avg. train loss: 0.06353\n",
      "Step #4300, epoch #12, avg. train loss: 0.05781\n",
      "Step #4400, epoch #12, avg. train loss: 0.06034\n",
      "Step #4500, epoch #12, avg. train loss: 0.06061\n",
      "Step #4600, epoch #13, avg. train loss: 0.06010\n",
      "Step #4700, epoch #13, avg. train loss: 0.05638\n",
      "Step #4800, epoch #13, avg. train loss: 0.05703\n",
      "Step #4900, epoch #14, avg. train loss: 0.05805\n",
      "Step #5000, epoch #14, avg. train loss: 0.05535\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TensorFlowDNNClassifier(batch_size=100, class_weight=None, clip_gradients=5.0,\n",
       "            config=None, continue_training=True, dropout=0.25,\n",
       "            hidden_units=[500, 200], learning_rate=0.001, n_classes=2,\n",
       "            optimizer='Adam', steps=5000, verbose=1)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.fit(pdl.tr, pdl.labels['fc']['tr'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DNN Classification train accuracy 0.98483284592, test accuracy 0.974023739893\n"
     ]
    }
   ],
   "source": [
    "PatchesSKLearner.print_accuracy(clf, pdl.tr, pdl.labels['fc']['tr'], pdl.t, pdl.labels['fc']['t'], \"DNN Classification\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DNN For Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "reg = skflow.TensorFlowDNNRegressor(hidden_units=[500, 200], batch_size=batch_size, steps=5000,\n",
    "                                    optimizer=\"Adam\", learning_rate=0.001, dropout=0.25, continue_training=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step #99, avg. train loss: 0.04443\n",
      "Step #199, avg. train loss: 0.02253\n",
      "Step #299, avg. train loss: 0.02157\n",
      "Step #400, epoch #1, avg. train loss: 0.02044\n",
      "Step #500, epoch #1, avg. train loss: 0.01968\n",
      "Step #600, epoch #1, avg. train loss: 0.01879\n",
      "Step #700, epoch #2, avg. train loss: 0.01895\n",
      "Step #800, epoch #2, avg. train loss: 0.01840\n",
      "Step #900, epoch #2, avg. train loss: 0.01765\n",
      "Step #1000, epoch #2, avg. train loss: 0.01812\n",
      "Step #1100, epoch #3, avg. train loss: 0.01744\n",
      "Step #1200, epoch #3, avg. train loss: 0.01705\n",
      "Step #1300, epoch #3, avg. train loss: 0.01742\n",
      "Step #1400, epoch #4, avg. train loss: 0.01682\n",
      "Step #1500, epoch #4, avg. train loss: 0.01630\n",
      "Step #1600, epoch #4, avg. train loss: 0.01656\n",
      "Step #1700, epoch #4, avg. train loss: 0.01677\n",
      "Step #1800, epoch #5, avg. train loss: 0.01612\n",
      "Step #1900, epoch #5, avg. train loss: 0.01612\n",
      "Step #2000, epoch #5, avg. train loss: 0.01574\n",
      "Step #2100, epoch #6, avg. train loss: 0.01591\n",
      "Step #2200, epoch #6, avg. train loss: 0.01537\n",
      "Step #2300, epoch #6, avg. train loss: 0.01552\n",
      "Step #2400, epoch #6, avg. train loss: 0.01526\n",
      "Step #2500, epoch #7, avg. train loss: 0.01508\n",
      "Step #2600, epoch #7, avg. train loss: 0.01478\n",
      "Step #2700, epoch #7, avg. train loss: 0.01478\n",
      "Step #2800, epoch #8, avg. train loss: 0.01492\n",
      "Step #2900, epoch #8, avg. train loss: 0.01477\n",
      "Step #3000, epoch #8, avg. train loss: 0.01445\n",
      "Step #3100, epoch #8, avg. train loss: 0.01448\n",
      "Step #3200, epoch #9, avg. train loss: 0.01438\n",
      "Step #3300, epoch #9, avg. train loss: 0.01413\n",
      "Step #3400, epoch #9, avg. train loss: 0.01397\n",
      "Step #3500, epoch #10, avg. train loss: 0.01417\n",
      "Step #3600, epoch #10, avg. train loss: 0.01345\n",
      "Step #3700, epoch #10, avg. train loss: 0.01399\n",
      "Step #3800, epoch #10, avg. train loss: 0.01387\n",
      "Step #3900, epoch #11, avg. train loss: 0.01351\n",
      "Step #4000, epoch #11, avg. train loss: 0.01340\n",
      "Step #4100, epoch #11, avg. train loss: 0.01359\n",
      "Step #4200, epoch #12, avg. train loss: 0.01351\n",
      "Step #4300, epoch #12, avg. train loss: 0.01301\n",
      "Step #4400, epoch #12, avg. train loss: 0.01339\n",
      "Step #4500, epoch #12, avg. train loss: 0.01355\n",
      "Step #4600, epoch #13, avg. train loss: 0.01325\n",
      "Step #4700, epoch #13, avg. train loss: 0.01278\n",
      "Step #4800, epoch #13, avg. train loss: 0.01280\n",
      "Step #4900, epoch #14, avg. train loss: 0.01293\n",
      "Step #5000, epoch #14, avg. train loss: 0.01256\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TensorFlowDNNRegressor(batch_size=100, clip_gradients=5.0, config=None,\n",
       "            continue_training=True, dropout=0.25, hidden_units=[500, 200],\n",
       "            learning_rate=0.001, n_classes=0, optimizer='Adam', steps=5000,\n",
       "            verbose=1)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg.fit(pdl.tr, pdl.labels['pfc_10']['tr'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DNN Regression PFC train accuracy 0.775900502456, test accuracy 0.747592332814\n"
     ]
    }
   ],
   "source": [
    "PatchesSKLearner.print_accuracy(reg, pdl.tr, pdl.labels['pfc_10']['tr'], pdl.t, pdl.labels['pfc_10']['t'], \"DNN Regression PFC\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DNN Regression PFC mse train mse 0.0228855780185, test mse 0.0254127871325\n"
     ]
    }
   ],
   "source": [
    "PatchesSKLearner.print_mse(reg, pdl.tr, pdl.labels['pfc_10']['tr'], pdl.t, pdl.labels['pfc_10']['t'], \"DNN Regression PFC mse\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "all_ferrari = np.r_[pdl.labels['ferrari']['tr'], pdl.labels['ferrari']['t']]\n",
    "n_ferrari_tr = pdl.labels['ferrari']['tr'].shape[0]\n",
    "ferrari_mean, ferrari_std = np.mean(all_ferrari), np.std(all_ferrari)\n",
    "all_ferrari_normalized = (all_ferrari - ferrari_mean) / ferrari_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ferrari_normalized_tr = all_ferrari_normalized[:n_ferrari_tr]\n",
    "ferrari_normalized_t = all_ferrari_normalized[n_ferrari_tr:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-5.62273625408e-17\n"
     ]
    }
   ],
   "source": [
    "print np.mean(all_ferrari_normalized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "reg_ferrari = skflow.TensorFlowDNNRegressor(hidden_units=[500, 200], batch_size=batch_size, steps=5000,\n",
    "                                    optimizer=\"Adam\", learning_rate=0.001, dropout=0.25, continue_training=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step #99, avg. train loss: 0.35687\n",
      "Step #199, avg. train loss: 0.27995\n",
      "Step #299, avg. train loss: 0.24340\n",
      "Step #400, epoch #1, avg. train loss: 0.22318\n",
      "Step #500, epoch #1, avg. train loss: 0.20634\n",
      "Step #600, epoch #1, avg. train loss: 0.20706\n",
      "Step #700, epoch #2, avg. train loss: 0.19558\n",
      "Step #800, epoch #2, avg. train loss: 0.18454\n",
      "Step #900, epoch #2, avg. train loss: 0.16887\n",
      "Step #1000, epoch #2, avg. train loss: 0.15048\n",
      "Step #1100, epoch #3, avg. train loss: 0.16090\n",
      "Step #1200, epoch #3, avg. train loss: 0.15292\n",
      "Step #1300, epoch #3, avg. train loss: 0.13893\n",
      "Step #1400, epoch #4, avg. train loss: 0.14952\n",
      "Step #1500, epoch #4, avg. train loss: 0.12793\n",
      "Step #1600, epoch #4, avg. train loss: 0.13439\n",
      "Step #1700, epoch #4, avg. train loss: 0.12794\n",
      "Step #1800, epoch #5, avg. train loss: 0.09988\n",
      "Step #1900, epoch #5, avg. train loss: 0.11308\n",
      "Step #2000, epoch #5, avg. train loss: 0.11836\n",
      "Step #2100, epoch #6, avg. train loss: 0.12537\n",
      "Step #2200, epoch #6, avg. train loss: 0.11563\n",
      "Step #2300, epoch #6, avg. train loss: 0.10652\n",
      "Step #2400, epoch #6, avg. train loss: 0.10955\n",
      "Step #2500, epoch #7, avg. train loss: 0.10170\n",
      "Step #2600, epoch #7, avg. train loss: 0.09509\n",
      "Step #2700, epoch #7, avg. train loss: 0.10069\n",
      "Step #2800, epoch #8, avg. train loss: 0.10696\n",
      "Step #2900, epoch #8, avg. train loss: 0.11302\n",
      "Step #3000, epoch #8, avg. train loss: 0.09625\n",
      "Step #3100, epoch #8, avg. train loss: 0.09204\n",
      "Step #3200, epoch #9, avg. train loss: 0.09977\n",
      "Step #3300, epoch #9, avg. train loss: 0.09052\n",
      "Step #3400, epoch #9, avg. train loss: 0.09651\n",
      "Step #3500, epoch #10, avg. train loss: 0.09241\n",
      "Step #3600, epoch #10, avg. train loss: 0.09258\n",
      "Step #3700, epoch #10, avg. train loss: 0.08861\n",
      "Step #3800, epoch #10, avg. train loss: 0.10092\n",
      "Step #3900, epoch #11, avg. train loss: 0.08848\n",
      "Step #4000, epoch #11, avg. train loss: 0.09141\n",
      "Step #4100, epoch #11, avg. train loss: 0.08084\n",
      "Step #4200, epoch #12, avg. train loss: 0.08798\n",
      "Step #4300, epoch #12, avg. train loss: 0.07797\n",
      "Step #4400, epoch #12, avg. train loss: 0.09301\n",
      "Step #4500, epoch #12, avg. train loss: 0.08236\n",
      "Step #4600, epoch #13, avg. train loss: 0.07547\n",
      "Step #4700, epoch #13, avg. train loss: 0.07836\n",
      "Step #4800, epoch #13, avg. train loss: 0.08186\n",
      "Step #4900, epoch #14, avg. train loss: 0.08533\n",
      "Step #5000, epoch #14, avg. train loss: 0.07556\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TensorFlowDNNRegressor(batch_size=100, clip_gradients=5.0, config=None,\n",
       "            continue_training=True, dropout=0.25, hidden_units=[500, 200],\n",
       "            learning_rate=0.001, n_classes=0, optimizer='Adam', steps=5000,\n",
       "            verbose=1)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg_ferrari.fit(pdl.tr, ferrari_normalized_tr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DNN Regression Ferrari Canny Normalized train accuracy 0.857218316759, test accuracy 0.834637472756\n"
     ]
    }
   ],
   "source": [
    "PatchesSKLearner.print_accuracy(reg_ferrari, pdl.tr, ferrari_normalized_tr, pdl.t, \n",
    "                                ferrari_normalized_t, \"DNN Regression Ferrari Canny Normalized\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DNN Regression Ferrari Canny Normalized mse train mse 0.142164454541, test mse 0.167477717333\n"
     ]
    }
   ],
   "source": [
    "PatchesSKLearner.print_mse(reg_ferrari, pdl.tr, ferrari_normalized_tr, pdl.t, \n",
    "                                ferrari_normalized_t, \"DNN Regression Ferrari Canny Normalized mse\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ferrari_preds_normalized_tr = reg_ferrari.predict(pdl.tr)\n",
    "ferrari_preds_normalized_t = reg_ferrari.predict(pdl.t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ferrari_preds_tr = (ferrari_preds_normalized_tr * ferrari_std) + ferrari_mean\n",
    "ferrari_preds_t = (ferrari_preds_normalized_t * ferrari_std) + ferrari_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DNN Regression Ferrari Canny train 0.857218318938, test 0.834637474128\n"
     ]
    }
   ],
   "source": [
    "print \"{0} train {1}, test {2}\".format(\"DNN Regression Ferrari Canny\", \n",
    "                                               r2_score(pdl.labels['ferrari']['tr'], ferrari_preds_tr), \n",
    "                                               r2_score(pdl.labels['ferrari']['t'], ferrari_preds_t))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DNN Regression Ferrari Canny train mse 4.12614773566e-08, test mse 4.86083396298e-08\n"
     ]
    }
   ],
   "source": [
    "print \"{0} train mse {1}, test mse {2}\".format(\"DNN Regression Ferrari Canny\", \n",
    "                                               mean_squared_error(pdl.labels['ferrari']['tr'], ferrari_preds_tr), \n",
    "                                               mean_squared_error(pdl.labels['ferrari']['t'], ferrari_preds_t))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
